{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac4fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#read data, and do word2vec\n",
    "def  data_Word2Vec(mixed_data):\n",
    "    Word2Vecmodel = gensim.models.KeyedVectors.load_word2vec_format('pre_trained.bin', \n",
    "                                                        unicode_errors='ignore', \n",
    "                                                        binary=True)\n",
    "    zero_array = np.zeros(100)  \n",
    "\n",
    "    for i in range(0 , len(mixed_data)):\n",
    "        try:\n",
    "            if i == 0:\n",
    "                docu_array = np.mean(model[mixed_data[i]] , axis=0)\n",
    "            else:\n",
    "                docu_array = np.vstack((docu_array , np.mean(model[mixed_data[i]] , axis=0) ))\n",
    "        \n",
    "        except KeyError as e:\n",
    "            print(repr(e))\n",
    "    return docu_array\n",
    "\n",
    "\n",
    "#do PCA,turn data into (len(data),1,2)\n",
    "def dataPCA(data):\n",
    "    docu2=data.reshape(len(data),100)\n",
    "    pca = PCA(n_components=2).fit_transform(docu2)\n",
    "    \n",
    "    x_lab = np.array(pca)\n",
    "    x_lab = x_lab.reshape(len(data),2)\n",
    "    return x_lab\n",
    "\n",
    "#do TSME,turn data into (len(data),1,2)\n",
    "def dataTSNE(data):\n",
    "    x_lab=[]\n",
    "    docu2=data.reshape((len(data),100))\n",
    "    tsne = TSNE(n_components=2, init='pca', perplexity=30).fit_transform(docu2)\n",
    "    \n",
    "    x_lab = np.array(tsne)\n",
    "    x_lab=x_lab.reshape((len(data),1,2))\n",
    "    return x_lab\n",
    "\n",
    "#input data from file 2:sub 3:time 7:views\n",
    "def readfromcsv(file,n):\n",
    "    with open(file,'r' ,  encoding='UTF-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        views = [row[n] for row in reader]    \n",
    "    del views[0]\n",
    "    return views\n",
    "\n",
    "#process ylabel's value, turn into integer, and divide by val (use after readfromcsv())\n",
    "def process_ylabel(views,val):\n",
    "    for i in range(len(views)):\n",
    "        n=int(views[i])\n",
    "        n=round(n/val)\n",
    "        views[i] = n\n",
    "    ylabel = np.array(views)\n",
    "    return ylabel\n",
    "\n",
    "#tim = readfromcsv(file,3)\n",
    "\n",
    "#process time's value into Numerical value, tim = original time  (use after readfromcsv())\n",
    "def process_time(tim):\n",
    "    #use the time when the data was scraped\n",
    "    timeString = \"2022-08-05 20:00:00\" # 時間格式為字串\n",
    "    struct_time = time.strptime(timeString, \"%Y-%m-%d %H:%M:%S\") # 轉成時間元組\n",
    "    time_stop = int(time.mktime(struct_time)) # 轉成時間戳\n",
    "    \n",
    "    timelist=[]\n",
    "    for i in tim:\n",
    "        struct_time = time.strptime(i, \"%Y/%m/%d %H:%M\")\n",
    "        time_stamp = int(time.mktime(struct_time))\n",
    "        timetonow = time_stop - time_stamp\n",
    "        timelist.append(timetonow)\n",
    "        \n",
    "#standardization, and reshape into 3 dimension\n",
    "    timedata = preprocessing.scale(timelist)\n",
    "    timedata=np.array(timedata)\n",
    "    \n",
    "    timedata=timedata.reshape((len(mixed_data),1))\n",
    "    return timedata    \n",
    "\n",
    "#join 2 different np.array, 3dimension:n=2, 2dimension:n=1\n",
    "def xlabel_join(docu2,timedata,n):\n",
    "    timedata=np.array(timedata)\n",
    "    x_label=np.append(docu2, timedata, axis = n )\n",
    "    return x_label\n",
    "\n",
    "#views = readfromcsv(file,2)\n",
    "\n",
    "#process_ylabel(views,100000)\n",
    "\n",
    "#join 2 different 2dimension np.array \n",
    "def process_sub(x_label,subs):\n",
    "    subarray=np.array(subs)\n",
    "    subdata=subarray.reshape((len(subarray),1))\n",
    "    x_label=np.append(x_label, subdata, axis = 1 )\n",
    "    return x_label\n",
    "\n",
    "#model input x_label, ylabel, n_features ex:( 1, 4),( 1, 102)\n",
    "def LSTMmodel(n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=10,input_shape=n_features))\n",
    "    model.add(Bidirectional(LSTM(50, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 1 ,activation=\"relu\"))\n",
    "    model.compile(loss='mse', optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "#train model\n",
    "#history = model.fit(x_train, y_train, epochs=10, batch_size=64 ,validation_data=((x_test, y_test)))\n",
    "\n",
    "#save model\n",
    "#model.save('rebest.h5')\n",
    "\n",
    "#show the first 100 train/test result\n",
    "def show_pred(model,x_train,y_train):\n",
    "    pred = model.predict(x_train) #訓練好model使用predict預測看看在訓練的model跑的回歸線\n",
    "\n",
    "    plt.plot(y_train[:100],'red' ,label='views')#畫出回歸線\n",
    "    plt.plot(pred[:100],label='Predicted views')\n",
    "    #plt.plot(x_train, y_train, 'o') #畫出原本的點\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Views')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a09295ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data, and do word2vec\n",
    "docu_array=data_Word2Vec(mixed_data)\n",
    "\n",
    "#reshape docu_array\n",
    "docu2=docu_array.reshape((len(docu_array),100))\n",
    "\n",
    "#csv file\n",
    "file=filename\n",
    "\n",
    "#data do TSNE\n",
    "x_lab =dataTSNE(docu2)\n",
    "\n",
    "#get ylabel\n",
    "views = read_fromcsv(file,7)\n",
    "ylabel = process_ylabel(views,100000)\n",
    "\n",
    "#get time label\n",
    "tim = read_fromcsv(file,3)\n",
    "timedata = process_time(tim)\n",
    "#join time data into xlabel and dimention =2 so n = 1\n",
    "x_label = xlabel_join(x_lab,timedata,1)\n",
    "\n",
    "#get sub label \n",
    "subs = read_fromcsv(file,2)\n",
    "subdata = process_ylabel(subs,100000)\n",
    "#join time data into xlabel and dimention =2 \n",
    "x_label = process_sub(x_label,subdata)\n",
    "\n",
    "x_label = x_label.reshape(len(x_label),1,4)\n",
    "\n",
    "#split into x,y train,test\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(x_label, ylabel, test_size=0.2)\n",
    "#generate model, input_shape=(1,4)\n",
    "model = LSTMmodel((1,4))\n",
    "\n",
    "#train model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64 ,validation_data=((x_test, y_test)))\n",
    "\n",
    "show_pred(model,x_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
